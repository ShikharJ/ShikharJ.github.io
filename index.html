<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron, Deepak Pathak, Saurabh Gupta and Aditya Kusupati*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 16px;
     font-weight: 400
  }
  heading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 19px;
     font-weight: 1000
  }
  strong {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 16px;
     font-weight: 800
  }
  strongred {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     color: 'red' ;
     font-size: 16px
  }
  sectionheading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 22px;
     font-weight: 600
  }
  pageheading {
     font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
     font-size: 38px;
     font-weight: 400
  }
  </style>
  <!-- <link rel="icon" type="image/png" href="images/W.png"> -->
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Shikhar Jaiswal</title>
  <meta name="Shikhar Jaiswal's Homepage" http-equiv="Content-Type" content="Shikhar Jaiswal's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
     <pageheading>Shikhar Jaiswal</pageheading><br>
     <b>email</b>:
     <font id="email" style="display:inline;">
        <noscript><i>Please enable Javascript to view</i></noscript>
     </font>
     <script>
     emailScramble = new scrambledString(document.getElementById('email'),
          'emailScramble', '@ootcro.wlaanjietu.sds',
          [8,13,15,12,9,14,18,11,5,7,2,6,16,1,3,20,17,22,19,4,21,10]);
     </script>
  </p>

  <tr>
     <td width="32%" valign="top"><a href="#Bio"><img src="images/portrait.png" width="100%" style="border-radius:15px"></a>
     <p align=center>
     <a href="pubs/CV.pdf" target="_blank">CV</a> | <a href="https://scholar.google.com/citations?user=5W3N29IAAAAJ&hl=en" target="_blank">Scholar</a> | <a href="https://github.com/ShikharJ" target="_blank">Github</a> | <a href="https://twitter.com/kharlikesticker" target="_blank">Twitter</a> <br>
     </p>
     </td>
     <td width="68%" valign="top" align="justify" id="Bio">
     <p> I am a CS PhD student at University of Toronto, fortunate to be advised by <a href="https://www.ricardobaptista.com/" target="_blank">Prof. Ricardo Baptista</a> and <a href="https://www.cs.toronto.edu/~erdogdu/" target="_blank">Prof. Murat Erdogdu</a>.
     <p> My current research interests include theoretical and practical aspects of Machine Learning for Systems and Systems for Machine Learning.</p>
     <p> Previously, I was a Research Fellow at Microsoft Research India, where I worked with <a href="https://harsha-simhadri.org/" target="_blank">Dr. Harsha Simhadri</a>, <a href="https://www.microsoft.com/en-us/research/people/rakri/" target="_blank">Dr. Ravishankar Krishnaswamy</a> and <a href="https://www.microsoft.com/en-us/research/people/rahsha/" target="_blank">Dr. Rahul Sharma</a> as a member of the <a href="https://www.microsoft.com/en-us/research/theme/foundations/" target="_blank">Algorithms</a> group.</p>
     <p> Long ago, I was a CS undergrad at IIT Patna.</p>
     </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td id="Preprints"> <sectionheading>&nbsp;&nbsp;Preprints</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
     <td width="33%" valign="top" align="center"><a href="https://arxiv.org/abs/2211.12850" target="_blank"><img src="images/ooddiskann.png" alt="OODDISKANN" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="https://arxiv.org/abs/2211.12850" target="_blank">
        <heading>OOD-DiskANN: Efficient and Scalable Graph ANNS for Out-of-Distribution Queries</heading></a><br>
        <strong>Shikhar Jaiswal</strong>, <a href="https://www.microsoft.com/en-us/research/people/rakri/" target="_blank">Ravishankar Krishnaswamy</a>, <a href="https://www.microsoft.com/en-us/research/people/garga/" target="_blank">Ankit Garg</a>, <a href="https://www.microsoft.com/en-us/research/people/harshasi/" target="_blank">Harsha Vardhan Simhadri</a>, <a href="https://www.linkedin.com/in/sheshansh-agrawal-b5a79b97/" target="_blank">Sheshansh Agrawal</a>
        </p>

        <div class="paper" id="ooddiskann">
        <a href="javascript:toggleblock('ooddiskannabs')">abstract</a> / 
        <a shape="rect" href="javascript:togglebib('ooddiskann')" class="togglebib">bibtex</a> / 
        <a href="https://arxiv.org/abs/2211.12850" target="_blank">paper</a>
        <br>

        <p align="justify"> <i id="ooddiskannabs">State-of-the-art algorithms for Approximate Nearest Neighbor Search (ANNS) such as DiskANN, FAISS, and HNSW build data dependent indices that offer substantially better accuracy and search efficiency over data-agnostic indices by overfitting to the index data distribution. When the query data is drawn from a different distribution, for example when index represents image embeddings and query represents textual embeddings, such algorithms lose much of this performance advantage. On a variety of datasets, for a fixed recall target, latency is worse by an order of magnitude or more for Out-Of-Distribution (OOD) queries as compared to In-Distribution (ID) queries. The question we address in this work is whether ANNS algorithms can be made efficient for OOD queries if the index construction is given access to a small sample set of these queries. We answer positively by presenting OOD-DiskANN, which uses a sparing sample (1% of index set size) of OOD queries, and provides up to 40% improvement in mean query latency over SoTA algorithms of a similar memory footprint. OOD-DiskANN is scalable and has the efficiency of graph-based ANNS indices. Some of our contributions can improve query efficiency for ID queries as well.</i></p>

<pre xml:space="preserve">
@misc{https://doi.org/10.48550/arxiv.2211.12850,
    doi = {10.48550/ARXIV.2211.12850},
    url = {https://arxiv.org/abs/2211.12850},
    author = {Jaiswal, Shikhar and Krishnaswamy,
      Ravishankar and Garg, Ankit and Simhadri,
      Harsha Vardhan and Agrawal, Sheshansh},
    keywords = {Machine Learning (cs.LG), Information
      Retrieval (cs.IR), FOS: Computer and information
      sciences, FOS: Computer and information sciences},
    title = {OOD-DiskANN: Efficient and Scalable Graph
      ANNS for Out-of-Distribution Queries},
    publisher = {arXiv},
    year = {2022},
    copyright = {Creative Commons Attribution 4.0
      International}
}</pre>
        </div>
      </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td id="ConferencePublications"> <sectionheading>&nbsp;&nbsp;Conference Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
     <td width="33%" valign="top" align="center"><a href="https://arxiv.org/abs/2210.16556" target="_blank"><img src="images/minun-overview.png" alt="MINUN" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="https://arxiv.org/abs/2210.16556" target="_blank">
        <heading>MinUn: Accurate ML Inference on Microcontrollers</heading></a><br>
        <strong>Shikhar Jaiswal</strong>*, <a href="https://krantikiran68.github.io" target="_blank">Rahul Kranti Kiran Goli</a>*, <a href="https://www.linkedin.com/in/aayan-kumar-a40969100/" target="_blank">Aayan Kumar</a>, <a href="https://www.microsoft.com/en-us/research/people/visesha/" target="_blank">Vivek Seshadri</a>, <a href="https://www.microsoft.com/en-us/research/people/rahsha/" target="_blank">Rahul Sharma</a> <br>
        International Conference on Languages, Compilers, and Tools for Embedded Systems (<strong>LCTES</strong>), 2023<br>
        </p>

        <div class="paper" id="minun">
        <a href="javascript:toggleblock('minunabs')">abstract</a> / 
        <a shape="rect" href="javascript:togglebib('minun')" class="togglebib">bibtex</a> / 
        <a href="https://dl.acm.org/doi/10.1145/3589610.3596278" target="_blank">paper</a> / 
        <a href="https://arxiv.org/abs/2210.16556" target="_blank">arxiv</a> / 
        <a href="https://github.com/ShikharJ/MinUn" target="_blank">code</a> / 
        <a href="https://youtu.be/zB12OC96ee8" target="_blank">talk</a> / 
        <a href="pubs/minun_ppt.pdf" target="_blank">slides</a> / 
        <a href="https://medium.com/towards-data-science/enabling-accurate-computer-vision-on-tiny-microcontrollers-with-rnnpool-operator-and-seedot-d6944930dcf9" target="_blank">blog</a>
        <br>

        <p align="justify"> <i id="minunabs">Running machine learning inference on tiny devices, known as TinyML, is an emerging research area. This task requires generating inference code that uses memory frugally, a task that standard ML frameworks are ill-suited for. A deployment framework for TinyML must be a) parametric in the number representation to take advantage of the emerging representations like posits, b) carefully assign high-precision to a few tensors so that most tensors can be kept in low-precision while still maintaining model accuracy, and c) avoid memory fragmentation. We describe MinUn, the first TinyML framework that holistically addresses these issues to generate efficient code for ARM microcontrollers (e.g., Arduino Uno, Due and STM32H747) that outperforms the prior TinyML frameworks.</i></p>

<pre xml:space="preserve">
@inproceedings{10.1145/3589610.3596278,
    author = {Jaiswal, Shikhar and Goli, Rahul Kranti
      Kiran and Kumar, Aayan and Seshadri, Vivek and
      Sharma, Rahul},
    title = {MinUn: Accurate ML Inference on
      Microcontrollers},
    year = {2023},
    isbn = {9798400701740},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3589610.3596278},
    doi = {10.1145/3589610.3596278},
    abstract = {Running machine learning inference on
      tiny devices, known as TinyML, is an emerging
      research area. This task requires generating
      inference code that uses memory frugally, a task
      that standard ML frameworks are ill-suited for. A
      deployment framework for TinyML must a) be
      parametric in the number representation to take
      advantage of the emerging representations like
      posits, b) carefully assign high-precision to a
      few tensors so that most tensors can be kept in
      low-precision while still maintaining model
      accuracy, and c) avoid memory fragmentation. We
      describe MinUn, the first TinyML framework that
      holistically addresses these issues to generate
      efficient code for ARM microcontrollers (e.g.,
      Arduino Uno, Due and STM32H747) that outperforms
      the prior TinyML frameworks.},
    booktitle = {Proceedings of the 24th ACM
      SIGPLAN/SIGBED International Conference on
      Languages, Compilers, and Tools for Embedded
      Systems},
    pages = {26–39},
    numpages = {14},
    keywords = {Number Representations, Memory
      Management, TinyML, Embedded Devices, Compilers,
      Programming Languages},
    location = {Orlando, FL, USA},
    series = {LCTES 2023}
}</pre>
        </div>
      </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <!-- <tr>
     <td width="33%" valign="top" align="center"><a href="pubs/drocc.pdf" target="_blank"><img src="images/drocc.PNG" alt="DROCC" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="pubs/drocc.pdf" target="_blank" id="drocc">
        <heading>DROCC: Deep Robust One-Class Classification</heading></a><br>
        <strong>Sachin Goyal</strong>, <a href="https://stanford.edu/~aditir/" target="_blank"> Aditi Raghunathan</a>, Moksh Jain, <a href="http://harsha-simhadri.org/" target="_blank"> Harsha Vardhan Simhadri </a>, <a href="https://www.prateekjain.org/" target="_blank"> Prateek Jain </a> <br>
        International Conference on Machine Learning (ICML), 2020<br>
        </p>

        <div class="paper" id="drocc">
        <a href="javascript:toggleblock('droccabs')">abstract</a> /
        <a href="https://proceedings.icml.cc/book/4293.pdf" target="_blank">paper</a> /
        <a href="https://github.com/microsoft/EdgeML" target="_blank">code</a> /
        <a href="https://www.youtube.com/watch?v=20pDzeSgSfw&t=789s" target="_blank">video</a>
        <br>

        <p align="justify"> <i id="droccabs">Classical approaches for one-class problems such as one-class SVM and isolation forest require careful feature engineering when applied to structured domains like images. State-of-the-art methods aim to leverage deep learning to learn appropriate features via two main approaches. The first approach based on predicting transformations (Golan & El-Yaniv, 2018; Hendrycks et al., 2019a) while successful in some domains, crucially depends on an appropriate domain-specific set of transformations that are hard to obtain in general. The second approach of minimizing a classical one-class loss on the learned final layer representations, e.g., DeepSVDD (Ruff et al., 2018) suffers from the fundamental drawback of representation collapse. In this work, we propose Deep Robust One Class Classification (DROCC) that is both applicable to most standard domains without requiring any side-information and robust to representation collapse. DROCC is based on the assumption that the points from the class of interest lie on a well-sampled, locally linear low dimensional manifold. Empirical evaluation demonstrates that DROCC is highly effective in two different one-class problem settings and on a range of real-world datasets across different domains: tabular data, images (CIFAR and ImageNet), audio, and time-series, offering up to 20% increase in accuracy over the state-of-the-art in anomaly detection. DROCC's code is available at <a href="https://github.com/Microsoft/EdgeML/">https://github.com/Microsoft/EdgeML/</a>.</i></p>

  </tr> -->
  <tr>
     <td width="33%" valign="top" align="center"><a href="https://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_29.pdf" target="_blank"><img src="images/smarte.png" alt="SMART-E" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="https://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_29.pdf" target="_blank">
        <heading>Acting Engaged: Leveraging Play Persona Archetypes for Semi-Supervised Classification of Engagement</heading></a><br>
        <a href="https://sites.google.com/site/benjaminnye/" target="_blank">Benjamin D. Nye</a>*, <a href="https://markcore.github.io/" target="_blank">Mark G. Core</a>*, <strong>Shikhar Jaiswal</strong>*, Aviroop Ghosal, Daniel Auerbach <br>
        International Conference on Educational Data Mining (<strong>EDM</strong>), 2021<br>
        </p>

        <div class="paper" id="smarte">
        <a href="javascript:toggleblock('smarteabs')">abstract</a> /
        <a shape="rect" href="javascript:togglebib('smarte')" class="togglebib">bibtex</a> /
        <a href="https://educationaldatamining.org/EDM2021/virtual/static/pdf/EDM21_paper_29.pdf" target="_blank">paper</a> /
        <a href="https://www.youtube.com/watch?v=335u9BB4Paw" target="_blank">talk</a> /
        <a href="pubs/smarte_ppt.pdf" target="_blank">slides</a>
        <br>

        <p align="justify"> <i id="smarteabs">Engaged and disengaged behaviors have been studied across a variety of educational contexts. However, tools to analyze engagement typically require custom-coding and calibration for a system. This limits engagement detection to systems where experts are available to study patterns and build detectors. This work studies a new approach to classify engagement patterns without expert input, by using a play persona methodology where labeled archetype data is generated by novice testers acting out different engagement patterns in a system. Domain-agnostic task features (e.g., response time to an activity, scores / correctness, task difficulty) are extracted from standardized data logs for both archetype and authentic user sessions. A semi-supervised methodology was used to label engagement; bottom-up clusters were combined with archetype data to build a classifier. This approach was analyzed with a focus on cold-start performance on small samples, using two metrics: consistency with larger full-sample cluster assignments and stability of points staying in the same cluster once assigned. These were compared against a baseline of clustering without an incrementally trained classifier. Findings on a data set from a branching multiple-choice scenario-based tutoring system indicated that approximately 52 unlabeled samples and 51 play-test labeled samples were sufficient to classify holdout sessions at 85% consistency with a full set of 145 unsupervised samples. Use-cases and limitations of this approach are also discussed.</p>

<pre xml:space="preserve">
@article{nyeacting,
    title={Acting Engaged: Leveraging Play Persona
      Archetypes for Semi-Supervised Classification of
      Engagement},
    author={Nye, Benjamin D and Core, Mark G and
      Jaiswal, Shikhar and Ghosal, Aviroop and Auerbach,
      Daniel},
    url={https://educationaldatamining.org/EDM2021/
      virtual/poster_paper29.html},
    booktitle = {Proceedings of the 14th International
      Conference on Educational Data Mining (EDM)},
    pages = {240--251},
    year = {2021}
}</pre>
        </div>
      </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <br/>
  <tr><td id="Workshop/Symposium/Software Papers"> <sectionheading>&nbsp;&nbsp;Workshop / Symposium / Software Papers </sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
     <td width="33%" valign="top" align="center"><a href="https://joss.theoj.org/papers/10.21105/joss.05026" target="_blank"><img src="images/joss.png" alt="MLPACK4" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="https://joss.theoj.org/papers/10.21105/joss.05026" target="_blank">
        <heading>mlpack 4: a fast, header-only C++ machine learning library</heading></a><br>
        mlpack Development Team <br> Journal of Open Source Software (<strong>JOSS</strong>), 2023 <br>
        </p>

        <div class="paper" id="mlpack4">
          <a href="javascript:toggleblock('mlpack4abs')">abstract</a> /
          <a shape="rect" href="javascript:togglebib('mlpack4')" class="togglebib">bibtex</a> /
          <a href="https://joss.theoj.org/papers/10.21105/joss.05026" target="_blank">paper</a>

        <p align="justify"> <i id="mlpack4abs">For over 15 years, the mlpack machine learning library has served as a "swiss army knife" for C++-based machine learning. Its efficient implementations of common and cutting-edge machine learning algorithms have been used in a wide variety of scientific and industrial applications. This paper overviews mlpack 4, a significant upgrade over its predecessor. The library has been significantly refactored and redesigned to facilitate an easier prototyping-to-deployment pipeline, including bindings to other languages (Python, Julia, R, Go, and the command line) that allow prototyping to be seamlessly performed in environments other than C++. </p>

<pre xml:space="preserve">
@article{mlpack2023,
    title     = {mlpack 4: a fast, header-only C++
      machine learning library},
    author    = {Ryan R. Curtin and Marcus Edel and
      Omar Shrit and Shubham Agrawal and Suryoday Basak
      and James J. Balamuta and Ryan Birmingham and
      Kartik Dutt and Dirk Eddelbuettel and Rishabh Garg
      and Shikhar Jaiswal and Aakash Kaushik and
      Sangyeon Kim and Anjishnu Mukherjee and Nanubala
      Gnana Sai and Nippun Sharma and Yashwant Singh
      Parihar and Roshan Swain and Conrad Sanderson},
    journal   = {Journal of Open Source Software},
    volume    = {8},
    number    = {82},
    pages     = {5026},
    year      = {2023},
    doi       = {10.21105/joss.05026},
    url       = {https://doi.org/10.21105/joss.05026}
}</pre>
        </div>
     </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
     <td width="33%" valign="top" align="center"><a href="https://gifttutoring.org/attachments/download/3708/giftsym8_proceedings.pdf#page=51" target="_blank"><img src="images/gift.png" alt="GIFT" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="https://gifttutoring.org/attachments/download/3708/giftsym8_proceedings.pdf#page=51" target="_blank">
        <heading>Integrating an Engagement Classification Pipeline into a GIFT
          Cybersecurity Module</heading></a><br>
        <a href="https://sites.google.com/site/benjaminnye/" target="_blank">Benjamin D. Nye</a>, <a href="https://markcore.github.io/" target="_blank">Mark G. Core</a>, Daniel Auerbach, Aviroop Ghosal, <strong>Shikhar Jaiswal</strong>, Milton Rosenberg <br> Eighth Annual GIFT Users Symposium (<strong>GIFTSym8</strong>), 2020 <br>
        </p>

        <div class="paper" id="gift">
          <a href="javascript:toggleblock('giftabs')">abstract</a> /
          <a shape="rect" href="javascript:togglebib('gift')" class="togglebib">bibtex</a> /
          <a href="https://gifttutoring.org/attachments/download/3708/giftsym8_proceedings.pdf#page=51" target="_blank">article</a> /
          <a href="pubs/gift_ppt.pdf" target="_blank">paper</a>

        <p align="justify"> <i id="giftabs">Measuring user engagement for learners is a critical problem in computer-based training. SMART-E classifies user engagement using a play-test methodology based on player personas - a small set of users acting out different engagement archetypes (e.g. dilligent, distracted, racing through). This archetype data is used as seed data for leveraging unlabeled user data for semi-supervised learning. In this paper, we describe our experiment in using SMART-E in the context of a GIFT cyber-security course. </p>

<pre xml:space="preserve">
@inproceedings{nye2020integrating,
    title = {Integrating an Engagement Classification
      Pipeline into a GIFT Cybersecurity Module},
    author = {Nye, Benjamin D and Core, Mark G and
      Auerbach, Daniel and Ghosal, Aviroop and Jaiswal,
      Shikhar and Rosenberg, Milton},
    booktitle = {Proceedings of the 8th Annual
      Generalized Intelligent Framework for Tutoring
      (GIFT) Users Symposium (GIFTSym8)},
    pages = {49},
    year = {2020},
    organization = {US Army Combat Capabilities
      Development Command--Soldier Center}
}</pre>
        </div>
     </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <br/>
  <tr><td id="Software"><sectionheading>&nbsp;&nbsp;Software (Team Collaboration)</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td width="33%" valign="top" align="center"><a href="https://github.com/mlpack/mlpack" target="_blank"><img src="https://cdn.rawgit.com/mlpack/mlpack.org/e7d36ed8/mlpack-black.svg" style="background-color:rgba(0,0,0,0);" alt="MLPACK" width="100%" style="border-radius:15px"></a>
      <td width="67%" valign="top">
        <p><a href="https://github.com/mlpack/mlpack" id="MLPack" target="_blank">
        <heading>mlpack: a fast, header-only machine learning library</heading></a><br>
        Github, MLPack Org, 2007-present.<br></p>

        <div class="paper" id="mlpack">
        <a href="javascript:toggleblock('mlpackabs')">abstract</a> /
        <a shape="rect" href="javascript:togglebib('mlpack')" class="togglebib">bibtex</a>

        <p align="justify"> <i id="mlpackabs">mlpack is an intuitive, fast, and flexible header-only C++ machine learning library. It is meant to be a machine learning analog to LAPACK, and aims to implement a wide array of machine learning methods and functions as a "swiss army knife" for machine learning researchers. mlpack's lightweight C++ implementation makes it ideal for deployment, and it can also be used for interactive prototyping via C++ notebooks (these can be seen in action on mlpack's homepage). In addition to its powerful C++ interface, mlpack also provides command-line programs, Python bindings, Julia bindings, Go bindings and R bindings.</i><br>mlpack is under 3-clause BSD license and is open to contributions and suggestions. Please <a shape="rect" href="javascript:togglebib('mlpack')" class="togglebib">cite</a> the software if you happen to use mlpack in your research or otherwise (use the latest bibtex from the <a href="https://github.com/mlpack/mlpack" id="mlpack" target="_blank">repository</a>).</p>

<pre xml:space="preserve">
@article{mlpack2023,
    title     = {mlpack 4: a fast, header-only C++
      machine learning library},
    author    = {Ryan R. Curtin and Marcus Edel and
      Omar Shrit and Shubham Agrawal and Suryoday Basak
      and James J. Balamuta and Ryan Birmingham and
      Kartik Dutt and Dirk Eddelbuettel and Rishabh Garg
      and Shikhar Jaiswal and Aakash Kaushik and
      Sangyeon Kim and Anjishnu Mukherjee and Nanubala
      Gnana Sai and Nippun Sharma and Yashwant Singh
      Parihar and Roshan Swain and Conrad Sanderson},
    journal   = {Journal of Open Source Software},
    volume    = {8},
    number    = {82},
    pages     = {5026},
    year      = {2023},
    doi       = {10.21105/joss.05026},
    url       = {https://doi.org/10.21105/joss.05026}
}</pre>
        </div>
     </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td width="33%" valign="top" align="center"><a href="https://github.com/microsoft/DiskANN" target="_blank"><img src="images/diskann.png" alt="DiskANN" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="https://github.com/microsoft/DiskANN" id="DiskANN" target="_blank">
        <heading>DiskANN: Graph-Structured Indices for Scalable, Fast, Fresh and Filtered Approximate Nearest Neighbor Search</heading></a><br>
        Github, Microsoft Research India, 2019-present.<br></p>

        <div class="paper" id="diskann">
        <a href="javascript:toggleblock('diskannabs')">abstract</a> /
        <a shape="rect" href="javascript:togglebib('diskann')" class="togglebib">bibtex</a>

        <p align="justify"> <i id="diskannabs">Repository for open-source implementations of DiskANN and Vamana algorithms in C++ for both Linux and Windows. DiskANN supports building and serving of SSD-based indices for k-ANNS queries on uint8, int8, and float datasets.</i><br>DiskANN is under MIT license and is open to contributions and suggestions. Please <a shape="rect" href="javascript:togglebib('diskann')" class="togglebib">cite</a> the software if you happen to use DiskANN in your research or otherwise (use the latest bibtex from the <a href="https://github.com/microsoft/DiskANN" id="DiskANN" target="_blank">repository</a>).</p>

<pre xml:space="preserve">
@misc{diskann-github,
  author = {Simhadri, Harsha Vardhan and Krishnaswamy,
    Ravishankar and Srinivasa, Gopal and Subramanya,
    Suhas Jayaram and Antonijevic, Andrija and Pryce,
    Dax and Kaczynski, David and Williams, Shane and
    Gollapudi, Siddarth and Sivashankar, Varun and
    Karia, Neel and Singh, Aditi and Jaiswal, Shikhar
    and Mahapatro, Neelam and Adams, Philip and
    Tower, Bryan},
  title = {{DiskANN: Graph-Structured Indices for
    Scalable, Fast, Fresh and Filtered Approximate Nearest
    Neighbor Search}},
  url = {https://github.com/Microsoft/DiskANN},
  version = {0.5},
  year = {2023}
}</pre>
        </div>
     </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td width="33%" valign="top" align="center"><a href="https://github.com/microsoft/EdgeML" target="_blank"><img src="images/edgeml.png" alt="EdgeML" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="https://github.com/microsoft/EdgeML" id="EdgeML" target="_blank">
        <heading>EdgeML: Machine Learning for Resource-Constrained Edge Devices</heading></a><br>
        Github, Microsoft Research India, 2017-present.<br></p>

        <div class="paper" id="edgeml">
        <a href="javascript:toggleblock('edgemlabs')">abstract</a> /
        <a shape="rect" href="javascript:togglebib('edgeml')" class="togglebib">bibtex</a>

        <p align="justify"> <i id="edgemlabs">Open-Source repository for all the research outputs on resource-efficient Machine Learning from Microsoft Research India. It contains scalable and multi-framework compatible implementations of Bonsai, ProtoNN, FastCells, EMI-RNN, ShaRNN, RNNPool, DROCC, and tools such as SeeDot, Shiftry and MinUn for memory efficient fixed-point and posit compilation of ML models along with applications such as on-device Keyword Spotting and GesturePod.</i><br>EdgeML is under MIT license and is open to contributions and suggestions. Please <a shape="rect" href="javascript:togglebib('edgeml')" class="togglebib">cite</a> the software if you happen to use EdgeML in your research or otherwise (use the latest bibtex from the <a href="https://github.com/microsoft/EdgeML" id="EdgeML" target="_blank">repository</a>).</p>

<pre xml:space="preserve">
@misc{edgeml04,
    author = {{Dennis, Don Kurian and Gaurkar, Yash
      and Gopinath, Sridhar and Goyal, Sachin and
      Gupta, Chirag and Jain, Moksh and Jaiswal, Shikhar
      and Kumar, Ashish and Kusupati, Aditya and 
      Lovett, Chris and Patil, Shishir G and
      Saha, Oindrila and Simhadri, Harsha Vardhan}},
    title = {{EdgeML: Machine Learning for
      Resource-Constrained Edge Devices}},
    url = {https://github.com/Microsoft/EdgeML},
    version = {0.4},
}</pre>
        </div>
     </td>
  </tr>
</table>

<!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <br/>
  <tr><td id="Theses"><sectionheading>&nbsp;&nbsp;Theses</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td width="33%" valign="top"><a href="pubs/Bachelors_Thesis.pdf" target="_blank"><img src="images/carnegie.png" alt="Thesis" width="100%" style="border-radius:15px"></a>
     <td width="67%" valign="top">
        <p><a href="pubs/Bachelors_Thesis.pdf" id="Thesis" target="_blank">
        <heading>Demand Forecasting Using Spectral Decomposition of Spatio-Temporal Origin-Destination Matrices</heading></a><br>
        <strong>Shikhar Jaiswal</strong>, under the guidance of <a href="https://www.iitp.ac.in/~joydeep/index.html" target="_blank"> Dr. Joydeep Chandra </a><br> 
        Undergraduate Thesis, CSE IIT Patna, 2019-20
        <br></p>

        <div class="paper" id="thesis">
        <a href="javascript:toggleblock('shikhar19abs')">abstract</a> /
        <a href="pubs/Bachelors_Thesis.pdf" target="_blank">pdf</a>

        <p align="justify"> <i id="shikhar19abs">The project aimed at studying the various state-of-the-art techniques applied to modelling passenger demands, and proposed new methods in achieving better results over the existing ideas. Additionally, we developed a full-featured interactive web application, through which users could gain real-time information on predicted traffic from the source and destination regions. </p>

        </div>
     </td>
  </tr>
</table> -->

<table width="100%" align="center" border="0" cellpadding="10">
  <tr><td id="Miscellaneous">
      <sectionheading>&nbsp;&nbsp;Miscellaneous</sectionheading>
      <ul>
      <li> I have an <a href="https://en.wikipedia.org/wiki/Erd%C5%91s_number" target="_blank">Erdős number</a> of 4 (Paul Erdős → Noga Alon → Moses Charikar → Ravi → Me).</li>
      <li> I was fortunate to work with <a href="https://sites.google.com/site/benjaminnye/" target="_blank">Dr. Benjamin D. Nye</a> and <a href="https://markcore.github.io/" target="_blank">Dr. Mark G. Core</a> at the <a href="https://ict.usc.edu/" target="_blank">USC Institute of Creative Technologies</a> in LA (Summer '19).</li>
      <li> I was quite active as an open-source developer during my undergrad. I participated in two iterations of <a href="https://summerofcode.withgoogle.com/" target="_blank">Google Summer of Code (GSoC)</a> at <a href="https://www.sympy.org/en/index.html" target="_blank">SymPy</a> and <a href="https://www.mlpack.org/" target="_blank">mlpack</a>, completed an internship at <a href="https://www.hackerrank.com/" target="_blank">Hackerrank</a>, and also worked on the <a href="https://www.openmainframeproject.org/" target="_blank">OpenMainframeProject</a>. I mentored two students for a later iteration of GSoC as well.</li>
      </ul>
  </td></tr>
</table>

<!-- <a href="https://info.flagcounter.com/Bdj6"><img src="https://s05.flagcounter.com/countxl/Bdj6/bg_FFFFFF/txt_000000/border_CCCCCC/columns_4/maxflags_12/viewers_0/labels_0/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a> -->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
     <tr><td><br><p align="right"><font size="2">
     Template: <a href="https://jonbarron.info">this</a>, <a href="https://people.eecs.berkeley.edu/~pathak/">this</a>, <a href="http://saurabhg.web.illinois.edu/">this</a> and <a href="https://homes.cs.washington.edu/~kusupati/">this</a>
     </font></p></td></tr>
</table>


  </td></tr>
</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('ooddiskannabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('minunabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('smarteabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('mlpack4abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('giftabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('mlpackabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('diskannabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('edgemlabs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('shikhar19abs');
</script>
</body>

</html>
